Chromesthesia is an interactive audio-visual experience that translates sound into color (WIP). Inspired by the neurological phenomenon where auditory stimuli involuntarily evoke visual perception of color, this project aims to explore the relationship between sound and sight through technology and design.

- Features

Real-time audio input analysis

Dynamic color generation based on pitch, volume, or timbre

Customizable visual themes and palettes

Web-based interface (or specify platform: mobile app, desktop, etc.)

- Technologies Used

[Insert framework or language, e.g., JavaScript, Web Audio API, Three.js, etc.]

[Add any libraries, e.g., Tone.js, p5.js, D3.js]

- Installation

git clone https://github.com/yourusername/chromesthesia.git
cd chromesthesia
npm install
npm run dev

- Usage

Open the app in your browser

Allow microphone access

Start speaking or playing music

Watch the visuals change in response to sound

Contributing

Contributions are welcome! Please open an issue or submit a pull request with suggestions or improvements.

- License

MIT

- Credits

Inspired by synesthetic experiences and works in sensory augmentation, digital art, and generative design.

